{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.model.models import MLP, Flow, Diffusion\n",
    "from src.data.helpers import get_accuracy, get_moons_dataset, rotate, generate_flow, generate_diffusion, list_to_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1c57270bfb43e2bb412116f78af14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 1000\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Model config\n",
    "input_dim = 2\n",
    "hidden_dims = [8]\n",
    "output_dim = 1\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Dataset\n",
    "X,y = get_moons_dataset()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Logging\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "epochs_till_convergence_clean = []\n",
    "\n",
    "# Training loop\n",
    "for i in tqdm(range(1000)):\n",
    "    angle = torch.randint(0, 360, (1,)).item()\n",
    "    X_rotated = rotate(X, angle)\n",
    "    X_tensor = torch.tensor(X_rotated, dtype=torch.float32).to(device)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "    model = MLP(input_dim=input_dim, hidden_dims=hidden_dims, output_dim=output_dim)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        loss = criterion(y_pred, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Eval loop\n",
    "        model.eval()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        correct = (y_pred.round() == y_tensor).sum().item()\n",
    "        accuracy = correct / len(y)\n",
    "\n",
    "        if(accuracy >= 0.95):\n",
    "            epochs_till_convergence_clean.append(epoch)\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d2e52dc2034020b0937044ccbb5ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Python\\master-thesis\\src\\data\\helpers.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param.data = torch.tensor(parameters_from_list, dtype=torch.float32).reshape(param.shape)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "flow = Flow()\n",
    "flow.load_state_dict(torch.load(\"../models/generators/flow_matching/flow_conditional.pth\"))\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 1000\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Model config\n",
    "input_dim = 2\n",
    "hidden_dims = [8]\n",
    "output_dim = 1\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Dataset\n",
    "X,y = get_moons_dataset()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Logging\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "epochs_till_convergence_flow = []\n",
    "\n",
    "# Training loop\n",
    "for i in tqdm(range(1000)):\n",
    "    angle = torch.randint(0, 360, (1,)).item()\n",
    "    X_rotated = rotate(X, angle)\n",
    "    X_tensor = torch.tensor(X_rotated, dtype=torch.float32).to(device)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "    model = MLP(input_dim=input_dim, hidden_dims=hidden_dims, output_dim=output_dim)\n",
    "    sample_parameters = generate_flow(flow, angle)\n",
    "    list_to_model(model, sample_parameters)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        loss = criterion(y_pred, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Eval loop\n",
    "        model.eval()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        correct = (y_pred.round() == y_tensor).sum().item()\n",
    "        accuracy = correct / len(y)\n",
    "\n",
    "        if(accuracy >= 0.95):\n",
    "            epochs_till_convergence_flow.append(epoch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772eac8ccafa4c699729ecc0ba366001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "diffusion = Diffusion()\n",
    "diffusion.load_state_dict(torch.load(\"../models/generators/diffusion/diffusion_conditional.pth\"))\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 1000\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Model config\n",
    "input_dim = 2\n",
    "hidden_dims = [8]\n",
    "output_dim = 1\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Dataset\n",
    "X,y = get_moons_dataset()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Logging\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "epochs_till_convergence_diffusion = []\n",
    "\n",
    "# Training loop\n",
    "for i in tqdm(range(1000)):\n",
    "    angle = torch.randint(0, 360, (1,)).item()\n",
    "    X_rotated = rotate(X, angle)\n",
    "    X_tensor = torch.tensor(X_rotated, dtype=torch.float32).to(device)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "    model = MLP(input_dim=input_dim, hidden_dims=hidden_dims, output_dim=output_dim)\n",
    "    sample_parameters = generate_diffusion(diffusion, angle)\n",
    "    list_to_model(model, sample_parameters)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        loss = criterion(y_pred, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Eval loop\n",
    "        model.eval()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        correct = (y_pred.round() == y_tensor).sum().item()\n",
    "        accuracy = correct / len(y)\n",
    "\n",
    "        if(accuracy >= 0.95):\n",
    "            epochs_till_convergence_diffusion.append(epoch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epochs for clean: 73.16203703703704\n",
      "Average epochs for flow: 2.5195195195195197\n",
      "Average epochs for diffusion: 0.818\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average epochs for clean: {np.mean(epochs_till_convergence_clean)}\")\n",
    "print(f\"Average epochs for flow: {np.mean(epochs_till_convergence_flow)}\")\n",
    "print(f\"Average epochs for diffusion: {np.mean(epochs_till_convergence_diffusion)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow matching trained with different samples per angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9bd0ca61c394aff91417d14876524c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 1000\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Model config\n",
    "input_dim = 2\n",
    "hidden_dims = [8]\n",
    "output_dim = 1\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Dataset\n",
    "X,y = get_moons_dataset()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Logging\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "epochs_till_convergence_clean = []\n",
    "\n",
    "# Training loop\n",
    "for i in tqdm(range(100)):\n",
    "    angle = torch.randint(0, 360, (1,)).item()\n",
    "    X_rotated = rotate(X, angle)\n",
    "    X_tensor = torch.tensor(X_rotated, dtype=torch.float32).to(device)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "    model = MLP(input_dim=input_dim, hidden_dims=hidden_dims, output_dim=output_dim)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        loss = criterion(y_pred, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Eval loop\n",
    "        model.eval()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        correct = (y_pred.round() == y_tensor).sum().item()\n",
    "        accuracy = correct / len(y)\n",
    "\n",
    "        if(accuracy >= 0.95):\n",
    "            epochs_till_convergence_clean.append(epoch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f514bdfe38e47869f468938ea118422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Projects\\Python\\master-thesis\\src\\data\\helpers.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  param.data = torch.tensor(parameters_from_list, dtype=torch.float32).reshape(param.shape)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "flow = Flow()\n",
    "flow.load_state_dict(torch.load(\"../models/generators/flow_matching/flow_conditional_10spa.pth\"))\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 1000\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Model config\n",
    "input_dim = 2\n",
    "hidden_dims = [8]\n",
    "output_dim = 1\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Dataset\n",
    "X,y = get_moons_dataset()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Logging\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "epochs_till_convergence_10spa = []\n",
    "\n",
    "# Training loop\n",
    "for i in tqdm(range(100)):\n",
    "    angle = torch.randint(0, 360, (1,)).item()\n",
    "    X_rotated = rotate(X, angle)\n",
    "    X_tensor = torch.tensor(X_rotated, dtype=torch.float32).to(device)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "    model = MLP(input_dim=input_dim, hidden_dims=hidden_dims, output_dim=output_dim)\n",
    "    sample_parameters = generate_flow(flow, angle)\n",
    "    list_to_model(model, sample_parameters)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        loss = criterion(y_pred, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Eval loop\n",
    "        model.eval()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        correct = (y_pred.round() == y_tensor).sum().item()\n",
    "        accuracy = correct / len(y)\n",
    "\n",
    "        if(accuracy >= 0.95):\n",
    "            epochs_till_convergence_10spa.append(epoch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e60b893f4b46858362ac3d057e9111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "flow = Flow()\n",
    "flow.load_state_dict(torch.load(\"../models/generators/flow_matching/flow_conditional_100spa.pth\"))\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 1000\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Model config\n",
    "input_dim = 2\n",
    "hidden_dims = [8]\n",
    "output_dim = 1\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Dataset\n",
    "X,y = get_moons_dataset()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Logging\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "epochs_till_convergence_100spa = []\n",
    "\n",
    "# Training loop\n",
    "for i in tqdm(range(100)):\n",
    "    angle = torch.randint(0, 360, (1,)).item()\n",
    "    X_rotated = rotate(X, angle)\n",
    "    X_tensor = torch.tensor(X_rotated, dtype=torch.float32).to(device)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "    model = MLP(input_dim=input_dim, hidden_dims=hidden_dims, output_dim=output_dim)\n",
    "    sample_parameters = generate_flow(flow, angle)\n",
    "    list_to_model(model, sample_parameters)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        loss = criterion(y_pred, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Eval loop\n",
    "        model.eval()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        correct = (y_pred.round() == y_tensor).sum().item()\n",
    "        accuracy = correct / len(y)\n",
    "\n",
    "        if(accuracy >= 0.95):\n",
    "            epochs_till_convergence_100spa.append(epoch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5f55f41a174b1ebc4e6710086a883c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "flow = Flow()\n",
    "flow.load_state_dict(torch.load(\"../models/generators/flow_matching/flow_conditional_1000spa.pth\"))\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 1000\n",
    "learning_rate = 0.05\n",
    "\n",
    "# Model config\n",
    "input_dim = 2\n",
    "hidden_dims = [8]\n",
    "output_dim = 1\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Dataset\n",
    "X,y = get_moons_dataset()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Logging\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "epochs_till_convergence_1000spa = []\n",
    "\n",
    "# Training loop\n",
    "for i in tqdm(range(100)):\n",
    "    angle = torch.randint(0, 360, (1,)).item()\n",
    "    X_rotated = rotate(X, angle)\n",
    "    X_tensor = torch.tensor(X_rotated, dtype=torch.float32).to(device)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "    model = MLP(input_dim=input_dim, hidden_dims=hidden_dims, output_dim=output_dim)\n",
    "    sample_parameters = generate_flow(flow, angle)\n",
    "    list_to_model(model, sample_parameters)\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        loss = criterion(y_pred, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Eval loop\n",
    "        model.eval()\n",
    "        y_pred = model(X_tensor).flatten()\n",
    "        correct = (y_pred.round() == y_tensor).sum().item()\n",
    "        accuracy = correct / len(y)\n",
    "\n",
    "        if(accuracy >= 0.95):\n",
    "            epochs_till_convergence_1000spa.append(epoch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([\"Clean\", \"10 SPA\", \"100 SPA\", \"1000 SPA\"], [np.mean(epochs_till_convergence_clean), np.mean(epochs_till_convergence_10spa), np.mean(epochs_till_convergence_100spa), np.mean(epochs_till_convergence_1000spa)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
