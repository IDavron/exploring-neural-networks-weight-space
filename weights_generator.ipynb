{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "from models import MLP\n",
    "from helpers import model_to_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset with our model parameters\n",
    "class ModelParamsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, parameters, label):\n",
    "        self.params = parameters\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.params)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.params[idx], self.label[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 576 models for training and 144 models for testing.\n"
     ]
    }
   ],
   "source": [
    "# Load all model parameters into one list\n",
    "models_path = \"models\"\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "saved_parameters = os.listdir(\"models\")\n",
    "for i, parameters in enumerate(saved_parameters):\n",
    "    model = MLP()\n",
    "    model.load_state_dict(torch.load(os.path.join(models_path, parameters)))\n",
    "    angle = parameters.split(\"_\")[1]\n",
    "\n",
    "    if(i % 10 < 8):\n",
    "        x_train.append(model_to_list(model))\n",
    "        y_train.append(int(int(angle)/5))\n",
    "    else:\n",
    "        x_test.append(model_to_list(model))\n",
    "        y_test.append(int(int(angle)/5))\n",
    "\n",
    "    \n",
    "print(f\"Loaded {len(x_train)} models for training and {len(x_test)} models for testing.\")\n",
    "\n",
    "# Create a dataset and dataloader\n",
    "dataset_train = ModelParamsDataset(x_train, y_train)\n",
    "dataset_test = ModelParamsDataset(x_test, y_test)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Autoencoder to generate weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reparameterize(mean, var):\n",
    "    std = torch.exp(0.5*var)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mean + eps*std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(151, 100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(100, 50),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.fc_mean = torch.nn.Linear(50, 10)\n",
    "        self.fc_var = torch.nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mean = self.fc_mean(x)\n",
    "        var = self.fc_var(x)\n",
    "\n",
    "        return mean, var\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 50),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(50, 100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(100, 151),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder: Encoder, decoder: Decoder):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, var  = self.encoder(x)\n",
    "        x = reparameterize(mean, var)\n",
    "        x = self.decoder(x)\n",
    "        return x, mean, var\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loss_function(x, x_hat, mean, var):\n",
    "    reconstruction_loss = nn.L1Loss(x, x_hat)\n",
    "    # kl_divergence = -0.5 * torch.sum(1 + var - mean.pow(2) - var.exp())\n",
    "    return reconstruction_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "autoencoder = Autoencoder(encoder, decoder)\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    total_loss = 0\n",
    "    for parameters in dataloader:\n",
    "        parameters = parameters.float()\n",
    "        pred, mean, var = autoencoder(parameters)\n",
    "        loss = total_loss_function(parameters, pred, mean, var)\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Loss: {total_loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
